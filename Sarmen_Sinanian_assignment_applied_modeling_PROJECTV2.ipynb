{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarmen-Sinanian-assignment_applied_modeling_ProjectV1.1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarmenSinanian/DS-Unit-2-Applied-Modeling/blob/master/Sarmen_Sinanian_assignment_applied_modeling_ProjectV1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nCc3XZEyG3XV"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Applied Modeling, Module 2\n",
        "\n",
        "You will use your portfolio project dataset for all assignments this sprint.\n",
        "\n",
        "## Assignment\n",
        "\n",
        "Complete these tasks for your project, and document your work.\n",
        "\n",
        "- [ ] Plot the distribution of your target. \n",
        "    - Regression problem: Is your target skewed? Then, log-transform it.\n",
        "    - Classification: Are your classes imbalanced? Then, don't use just accuracy. And try `class_balance` parameter in scikit-learn.\n",
        "- [ ] Continue to clean and explore your data. Make exploratory visualizations.\n",
        "- [ ] Fit a model. Does it beat your baseline?\n",
        "- [ ] Share at least 1 visualization on Slack.\n",
        "\n",
        "You need to complete an initial model today, because the rest of the week, we're making model interpretation visualizations.\n",
        "\n",
        "\n",
        "## Reading\n",
        "\n",
        "### Today\n",
        "- [imbalance-learn](https://github.com/scikit-learn-contrib/imbalanced-learn)\n",
        "- [Learning from Imbalanced Classes](https://www.svds.com/tbt-learning-imbalanced-classes/)\n",
        "- [Machine Learning Meets Economics](http://blog.mldb.ai/blog/posts/2016/01/ml-meets-economics/)\n",
        "- [ROC curves and Area Under the Curve explained](https://www.dataschool.io/roc-curves-and-auc-explained/)\n",
        "- [The philosophical argument for using ROC curves](https://lukeoakdenrayner.wordpress.com/2018/01/07/the-philosophical-argument-for-using-roc-curves/)\n",
        "\n",
        "\n",
        "### Yesterday\n",
        "- [Attacking discrimination with smarter machine learning](https://research.google.com/bigpicture/attacking-discrimination-in-ml/), by Google Research, with  interactive visualizations. _\"A threshold classifier essentially makes a yes/no decision, putting things in one category or another. We look at how these classifiers work, ways they can potentially be unfair, and how you might turn an unfair classifier into a fairer one. As an illustrative example, we focus on loan granting scenarios where a bank may grant or deny a loan based on a single, automatically computed number such as a credit score.\"_\n",
        "- [How Shopify Capital Uses Quantile Regression To Help Merchants Succeed](https://engineering.shopify.com/blogs/engineering/how-shopify-uses-machine-learning-to-help-our-merchants-grow-their-business)\n",
        "- [Maximizing Scarce Maintenance Resources with Data: Applying predictive modeling, precision at k, and clustering to optimize impact](https://towardsdatascience.com/maximizing-scarce-maintenance-resources-with-data-8f3491133050), **by Lambda DS3 student** Michael Brady. His blog post extends the Tanzania Waterpumps scenario, far beyond what's in the lecture notebook.\n",
        "- [Notebook about how to calculate expected value from a confusion matrix by treating it as a cost-benefit matrix](https://github.com/podopie/DAT18NYC/blob/master/classes/13-expected_value_cost_benefit_analysis.ipynb)\n",
        "- [Simple guide to confusion matrix terminology](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/) by Kevin Markham, with video\n",
        "- [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wM0ChIkGuVAp",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# conda install -c conda-forge category_encoders\n",
        "# conda update -n base -c defaults conda\n",
        "# pip install --upgrade category_encoders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPoBKvNKOAC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQuvfrCsOADA",
        "colab_type": "text"
      },
      "source": [
        "# BELOW DATASET FROM https://query1.finance.yahoo.com/v7/finance/download/SPY?period1=728294400&period2=1566889200&interval=1d&events=history&crumb=ixT1ci5YI3E"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxAjV9xiOADB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "511604e9-7994-45a8-9062-5e108fdd33ea"
      },
      "source": [
        "# Setting specific columns to use (using unadjusted close and not\n",
        "#  accounting for the splits and dividends)\n",
        "columns = ['Date','Close','Volume']\n",
        "\n",
        "# Calling data set\n",
        "spy = pd.read_csv(r'E:\\Desktop\\Lambda_School\\Assignments\\Unit 2 Sprint 7 PROJECT\\SPY.csv',\n",
        "                  usecols = columns)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c8b24ae6d565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Calling data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m spy = pd.read_csv(r'E:\\Desktop\\Lambda_School\\Assignments\\Unit 2 Sprint 7 PROJECT\\SPY.csv',\n\u001b[0;32m----> 5\u001b[0;31m                   usecols = columns)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'E:\\\\Desktop\\\\Lambda_School\\\\Assignments\\\\Unit 2 Sprint 7 PROJECT\\\\SPY.csv' does not exist: b'E:\\\\Desktop\\\\Lambda_School\\\\Assignments\\\\Unit 2 Sprint 7 PROJECT\\\\SPY.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKu8uP0iOADD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking columns\n",
        "spy.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdg_6BJpOADH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p49bAE8OADJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuS3USQcOADM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp8pR6bpOADO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Changing Dat to datetime format\n",
        "spy['Date'] = pd.to_datetime(spy['Date'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKCI9z4UOADQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizing total dataset without volumne\n",
        "\n",
        "plt.plot_date(spy['Date'], spy['Close'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vCFxE6hqF3P9"
      },
      "source": [
        "# Choose your target. Which column in your tabular dataset will you predict?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xeQxfCIOADT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  PRICE(CLOSE) NEXT DAY ABOVE/BELOW PREVIOUS DAY BASED ON ROLLING MEAN(SMA) OR RELATIVE STRENGTH (RSI)***"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iGhy2o9MF5iK"
      },
      "source": [
        "# Choose which observations you will use to train, validate, and test your model. And which observations, if any, to exclude.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sINbwGqxOADW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#*WILL USE ALL SPY (S&P 500 ETF) DATA*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KwGWGEUZF5e4"
      },
      "source": [
        "# Determine whether your problem is regression or classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7QT56P4OADZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# *CLASSIFICATION (IS THIS TICKER OVER/UNDER THE X_DAY ROLLING MEAN ***AND*** ALSO OVER/UNDER BOUGHT ON THE RSI?)*\n",
        "# *AKA 3 WAY CONFUSION MATRIX WITH UNDER TO BOTH AS THE HIGHEST LIKELIHOOD PREDICTOR OF NEXT DAY/WEEKS/MONTHS POSITIVE RETURNS*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OE4NpAxhF5bJ"
      },
      "source": [
        "# Choose your evaluation metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4DSkVH_OADc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WILL USE ACCURACY SCORE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k2-7u08UF5Xo"
      },
      "source": [
        "# Begin with baselines: majority class baseline for classification, or mean baseline for regression, with your metric of choice.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9oRWOInOADg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBccYcR4OADi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhJEpZTPOADl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8N3dDShOADn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy['Date'] = pd.to_datetime(spy['Date'])\n",
        "spy['Year'] = spy['Date'].dt.year"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKQPsUGYOADw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SWd1IO8OAD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwj__Fv2OAD3",
        "colab_type": "text"
      },
      "source": [
        "### *NEITHER .ROLLING_MEAN NOR .ROLLING WORK*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSLf627GOAD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spy['SMA'] = spy['Close'].rolling(window = 14, min_periods = 14, axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAekD4oHOAD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spy['SMA'] = pd.rolling_mean(spy['Close'], min_periods = 14, window = 14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK7UqXPHOAD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofmGSYQLOAD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTzrOSyBOAD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kT3JOVRDOAEB"
      },
      "source": [
        "# Begin with baselines: majority class baseline for classification, or mean baseline for regression, with your metric of choice.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpw_vPkrOAEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy['SMA'] = spy.Close.rolling(window=14).mean()\n",
        "spy['SMA_Yesterday'] = spy['SMA'].shift(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMHviMg1OAED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.head(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg2K3SGPOAEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LET0npPOAEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wESRbYxnOAEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN00XYKrOAEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spy['Close_Higher'] = np.where(spy['Close'] > spy['Close'].shift(-1), 'True','False')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UutGcoNPOAEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spy_numeric = ['Close']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0kSXqpTOAEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy['Above_14D_SMA_Yesterday'] = np.where(spy['SMA'].shift(1)<spy['Close'].shift(1), 0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urdc1M2LOAEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy['Below_14D_SMA_Yesterday'] = np.where(spy['SMA'].shift(1)>spy['Close'].shift(1), 0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X--OeJKhOAER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spy['Above_14D_SMA_Yesterday'] = np.where(spy['SMA']>spy['Close'], 'True','False')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3Sa-mOjmOAEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.Above_14D_SMA_Yesterday.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc052CPeOAEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy_numeric_diff = spy[['Close']].diff()[1:]\n",
        "# cond1 = spy_numeric_diff[['Close']] >=0\n",
        "spy['Close_Higher_Than_Yesterday'] = np.insert(np.where(spy_numeric_diff[['Close']] >=0, '1','0'), 0, np.nan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOguyHkVOAEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.Close_Higher_Than_Yesterday.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwqt7iKeOAEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = spy['Close_Higher_Than_Yesterday']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pftim0OPOAEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "majority_class = y_train.mode()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPxJ2tU6OAEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = [majority_class]*len(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euJF0jQpOAEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QdLb-a_MF5ST"
      },
      "source": [
        "# Begin to clean and explore your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS_TJznIOAEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy_2019 = spy[spy['Year'] == 2019]\n",
        "spy_2018 = spy[spy['Year'] == 2018]\n",
        "spy_2017 = spy[spy['Year'] == 2017]\n",
        "spy_2016 = spy[spy['Year'] == 2016]\n",
        "spy_2015 = spy[spy['Year'] == 2015]\n",
        "spy_2014 = spy[spy['Year'] == 2014]\n",
        "spy_2013 = spy[spy['Year'] == 2013]\n",
        "spy_2012 = spy[spy['Year'] == 2012]\n",
        "spy_2011 = spy[spy['Year'] == 2011]\n",
        "spy_2010 = spy[spy['Year'] == 2010]\n",
        "spy_2009 = spy[spy['Year'] == 2009]\n",
        "spy_2008 = spy[spy['Year'] == 2008]\n",
        "spy_2007 = spy[spy['Year'] == 2007]\n",
        "spy_2006 = spy[spy['Year'] == 2006]\n",
        "spy_2005 = spy[spy['Year'] == 2005]\n",
        "spy_2004 = spy[spy['Year'] == 2004]\n",
        "spy_2003 = spy[spy['Year'] == 2003]\n",
        "spy_2002 = spy[spy['Year'] == 2002]\n",
        "spy_2001 = spy[spy['Year'] == 2001]\n",
        "spy_2000 = spy[spy['Year'] == 2000]\n",
        "spy_1999 = spy[spy['Year'] == 1999]\n",
        "spy_1998 = spy[spy['Year'] == 1998]\n",
        "spy_1997 = spy[spy['Year'] == 1997]\n",
        "spy_1996 = spy[spy['Year'] == 1996]\n",
        "spy_1995 = spy[spy['Year'] == 1995]\n",
        "spy_1994 = spy[spy['Year'] == 1994]\n",
        "spy_1993 = spy[spy['Year'] == 1993]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QJFI1FVOAEm",
        "colab_type": "text"
      },
      "source": [
        "# Plot the distribution of your target.\n",
        "### Regression problem: Is your target skewed? Then, log-transform it.\n",
        "### Classification: Are your classes imbalanced? Then, don't use just accuracy. And try class_balance parameter in scikit-learn.\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jre4gE4gOAEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.tail(25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmJ3ea96OAEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy_1994_2013 = pd.concat([spy_1994,spy_1995,spy_1996,spy_1997,spy_1998,\n",
        "                           spy_1999,spy_2000,spy_2001,spy_2002,spy_2003,\n",
        "                           spy_2004,spy_2005,spy_2006,spy_2007,spy_2008,\n",
        "                           spy_2009,spy_2010,spy_2011,spy_2012,spy_2013])\n",
        "spy_1994_2013.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAv__qugOAEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = ['Close_Higher_Than_Yesterday']\n",
        "drop = ['Date','Year']\n",
        "\n",
        "\n",
        "train = spy_1994_2013.drop(columns=drop)\n",
        "test = spy_2017.drop(columns=drop)\n",
        "val = spy_2019.drop(columns=drop)\n",
        "\n",
        "X_val = val.drop(columns=target)\n",
        "y_val = val[target]\n",
        "\n",
        "X_test = test.drop(columns=target)\n",
        "y_test = test[target]\n",
        "\n",
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_gTNmicOAEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU-9SNUhOAEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu1W0axYOAEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('MAJORITY CLASS Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sukZ3HSOAEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "y_pred = pipeline.predict(X_val)\n",
        "\n",
        "confusion_matrix(y_val, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5fnm867OAEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    labels = unique_labels(y_true)\n",
        "    columns = [f'Predicted {label}' for label in labels]\n",
        "    index = [f'Actual {label}' for label in labels]\n",
        "    return columns, index\n",
        "\n",
        "plot_confusion_matrix(y_val, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euqO2W4nOAE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    labels = unique_labels(y_true)\n",
        "    columns = [f'Predicted {label}' for label in labels]\n",
        "    index = [f'Actual {label}' for label in labels]\n",
        "    table = pd.DataFrame(confusion_matrix(y_true, y_pred),\n",
        "                         columns=columns, index=index)\n",
        "    return table\n",
        "\n",
        "plot_confusion_matrix(y_val, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fqz9IVxOAE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    labels = unique_labels(y_true)\n",
        "    columns = [f'Predicted {label}' for label in labels]\n",
        "    index = [f'Actual {label}' for label in labels]\n",
        "    table = pd.DataFrame(confusion_matrix(y_true, y_pred),\n",
        "                         columns=columns, index=index)\n",
        "    return sns.heatmap(table, annot=True, fmt='d', cmap='viridis')\n",
        "\n",
        "plot_confusion_matrix(y_val, y_pred);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xgmlzHuOAE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fGOn-jEOAE5",
        "colab_type": "text"
      },
      "source": [
        "# Continue to clean and explore your data. Make exploratory visualizations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4f7mTQ3OAE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "Close = spy['Close']\n",
        "\n",
        "# Get the difference in price from previous step\n",
        "\n",
        "delta = Close.diff()\n",
        "\n",
        "# Get rid of the first row, which is NaN since it did not have a previous \n",
        "# row to calculate the differences\n",
        "delta = delta[1:] \n",
        "\n",
        "# Make the positive gains (up) and negative gains (down) Series\n",
        "up, down = delta.copy(), delta.copy()\n",
        "up[up < 0] = 0\n",
        "down[down > 0] = 0\n",
        "\n",
        "# # Calculate the EWMA\n",
        "\n",
        "spy['Roll_Up'] = up.shift(1)\n",
        "spy['Roll_Down'] = down.abs().shift(1)\n",
        "\n",
        "spy['Roll_Up1'] = spy['Roll_Up'].ewm(com=7).mean()\n",
        "spy['Roll_Down1'] = spy['Roll_Down'].ewm(com=7).mean()\n",
        "\n",
        "# # Calculate the RSI based on EWMA\n",
        "\n",
        "RS1 = spy['Roll_Up1'] / spy['Roll_Down1']\n",
        "RSI1 = 100.0 - (100.0 / (1.0 + RS1))\n",
        "\n",
        "spy['RSI_Yesterday_EXP'] = RSI1\n",
        "\n",
        "# Calculate the SMA\n",
        "spy['Roll_Up2'] = spy['Roll_Up'].rolling(window = 7).mean()\n",
        "spy['Roll_Down2'] = spy['Roll_Down'].rolling(window = 7).mean()\n",
        "\n",
        "# Calculate the RSI based on SMA\n",
        "RS2 = spy['Roll_Up2'] / spy['Roll_Down2']\n",
        "RSI2 = 100.0 - (100.0 / (1.0 + RS2))\n",
        "\n",
        "spy['RSI_Yesterday_SMA'] = RSI2\n",
        "\n",
        "# Compare graphically\n",
        "plt.figure()\n",
        "RSI1.plot()\n",
        "RSI2.plot()\n",
        "plt.legend(['RSI via EWMA', 'RSI via SMA'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMk7nTCiOAE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5sTPOvt0OAE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-4RojnJOAFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBTmz5AAOAFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy['Overbought_Yesterday_EXP'] = spy['RSI_Yesterday_EXP'].shift(1) > 70.0\n",
        "spy['Oversold_Yesterday_EXP'] = spy['RSI_Yesterday_EXP'].shift(1) < 30.0\n",
        "\n",
        "spy['Overbought_Yesterday_SMA'] = spy['RSI_Yesterday_SMA'].shift(1) > 70.0\n",
        "spy['Oversold_Yesterday_SMA'] = spy['RSI_Yesterday_SMA'].shift(1) < 30.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xie9wIbOAFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy['Overbought_Yesterday_EXP'].replace(to_replace=False,value=0, inplace=True)\n",
        "spy['Oversold_Yesterday_EXP'].replace(to_replace=False,value=0, inplace=True)\n",
        "\n",
        "spy['Overbought_Yesterday_SMA'].replace(to_replace=False,value=0, inplace=True)\n",
        "spy['Oversold_Yesterday_SMA'].replace(to_replace=False,value=0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LMtAm6ixOAFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TgbXk5DOAFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy['Oversold_EXP_And_Under_14D_SMA_Yesterday'] = ((spy['Oversold_Yesterday_EXP'] ==1) & (spy['Below_14D_SMA_Yesterday'] == 0))\n",
        "spy['Oversold_SMA_And_Under_14D_SMA_Yesterday'] = ((spy['Oversold_Yesterday_SMA'] ==1) & (spy['Below_14D_SMA_Yesterday'] == 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uNWGVV3OAFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy['Oversold_EXP_And_Under_14D_SMA_Yesterday'].replace(to_replace=False,value=0, inplace=True)\n",
        "spy['Oversold_SMA_And_Under_14D_SMA_Yesterday'].replace(to_replace=False,value=0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Yajh_bOAFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "652bODqQOAFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.Oversold_EXP_And_Under_14D_SMA_Yesterday.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2kc6Pl1OAFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.Oversold_SMA_And_Under_14D_SMA_Yesterday.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0udARmQOAFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy['Volume_Yesterday'] = spy['Volume'].shift(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "506vf7l0OAFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy_2019 = spy[spy['Year'] == 2019]\n",
        "spy_2018 = spy[spy['Year'] == 2018]\n",
        "spy_2017 = spy[spy['Year'] == 2017]\n",
        "spy_2016 = spy[spy['Year'] == 2016]\n",
        "spy_2015 = spy[spy['Year'] == 2015]\n",
        "spy_2014 = spy[spy['Year'] == 2014]\n",
        "spy_2013 = spy[spy['Year'] == 2013]\n",
        "spy_2012 = spy[spy['Year'] == 2012]\n",
        "spy_2011 = spy[spy['Year'] == 2011]\n",
        "spy_2010 = spy[spy['Year'] == 2010]\n",
        "spy_2009 = spy[spy['Year'] == 2009]\n",
        "spy_2008 = spy[spy['Year'] == 2008]\n",
        "spy_2007 = spy[spy['Year'] == 2007]\n",
        "spy_2006 = spy[spy['Year'] == 2006]\n",
        "spy_2005 = spy[spy['Year'] == 2005]\n",
        "spy_2004 = spy[spy['Year'] == 2004]\n",
        "spy_2003 = spy[spy['Year'] == 2003]\n",
        "spy_2002 = spy[spy['Year'] == 2002]\n",
        "spy_2001 = spy[spy['Year'] == 2001]\n",
        "spy_2000 = spy[spy['Year'] == 2000]\n",
        "spy_1999 = spy[spy['Year'] == 1999]\n",
        "spy_1998 = spy[spy['Year'] == 1998]\n",
        "spy_1997 = spy[spy['Year'] == 1997]\n",
        "spy_1996 = spy[spy['Year'] == 1996]\n",
        "spy_1995 = spy[spy['Year'] == 1995]\n",
        "spy_1994 = spy[spy['Year'] == 1994]\n",
        "spy_1993 = spy[spy['Year'] == 1993]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF3WxkKhOAFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy_1994_2013 = spy[(spy['Year'] >= 1994) & (spy['Year'] <=2013)]\n",
        "spy_1994_2017 = spy[(spy['Year'] >= 1994) & (spy['Year'] <=2017)]\n",
        "spy_2014_2019 = spy[(spy['Year'] >=2014) & (spy['Year'] <=2019)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ge8gywTOAFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy_2010_2013 = pd.concat([spy_2010,spy_2011,spy_2012,spy_2013])\n",
        "spy_2010_2013.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p4Vfe76OAFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy_2010_2013.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7FC5JAvOAFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2018 training data\n",
        "\n",
        "# 0.0091 ± 0.0183\tSMA_Yesterday\n",
        "# 0.0061 ± 0.0000\tOversold_SMA_And_Under_14D_SMA_Yesterday\n",
        "# 0.0061 ± 0.0000\tOversold_Yesterday_SMA\n",
        "# 0 ± 0.0000\tOversold_EXP_And_Under_14D_SMA_Yesterday\n",
        "# 0 ± 0.0000\tOversold_Yesterday_EXP\n",
        "# -0.0030 ± 0.0183\tOverbought_Yesterday_SMA\n",
        "# -0.0061 ± 0.0000\tAbove_14D_SMA_Yesterday\n",
        "# -0.0091 ± 0.0183\tOverbought_Yesterday_EXP\n",
        "# -0.0091 ± 0.0427\tRSI_Yesterday_SMA\n",
        "# -0.0091 ± 0.0305\tBelow_14D_SMA_Yesterday\n",
        "# -0.0122 ± 0.0488\tVolume_Yesterday\n",
        "# -0.0213 ± 0.0427\tRSI_Yesterday_EXP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKIFgwMiOAFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1994-2013 training data\n",
        "\n",
        "# 0 ± 0.0000\tOversold_Yesterday_EXP\n",
        "# 0 ± 0.0000\tSMA_Yesterday\n",
        "# 0 ± 0.0000\tYear\n",
        "# -0.0040 ± 0.0000\tOversold_EXP_And_Under_14D_SMA_Yesterday\n",
        "# -0.0040 ± 0.0000\tOverbought_Yesterday_EXP\n",
        "# -0.0060 ± 0.0120\tOversold_SMA_And_Under_14D_SMA_Yesterday\n",
        "# -0.0159 ± 0.0159\tOverbought_Yesterday_SMA\n",
        "# -0.0199 ± 0.0000\tRSI_Yesterday_EXP\n",
        "# -0.0219 ± 0.0120\tVolume_Yesterday"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNswZq02OAFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BELOW IS THE DROP FOR TRAIN 1994-2013 AND VAL 2019\n",
        "\n",
        "# 0.0823 ± 0.0427\tOverbought_Yesterday_SMA\n",
        "# 0.0671 ± 0.0366\tRSI_Yesterday_EXP\n",
        "# 0.0549 ± 0.0122\tRSI_Yesterday_SMA\n",
        "# 0.0335 ± 0.0061\tAbove_14D_SMA_Yesterday\n",
        "# 0.0305 ± 0.0000\tBelow_14D_SMA_Yesterday\n",
        "# 0.0061 ± 0.0122\tOverbought_Yesterday_EXP\n",
        "# 0 ± 0.0000\tVolume_Yesterday\n",
        "# 0 ± 0.0000\tOversold_SMA_And_Under_14D_SMA_Yesterday\n",
        "# 0 ± 0.0000\tOversold_EXP_And_Under_14D_SMA_Yesterday\n",
        "# 0 ± 0.0000\tOversold_Yesterday_EXP\n",
        "# 0 ± 0.0000\tSMA_Yesterday\n",
        "# -0.0030 ± 0.0061\tOversold_Yesterday_SMA\n",
        "\n",
        "# DROP BELOW AFTER TRAINING/VAL PERMUTATION IMPORTANCE\n",
        "\n",
        "# 0.0030 ± 0.0305\tOverbought_Yesterday_SMA\n",
        "# 0.0030 ± 0.0061\tOverbought_Yesterday_EXP\n",
        "# -0.0030 ± 0.0061\tBelow_14D_SMA_Yesterday\n",
        "# -0.0457 ± 0.0793\tRSI_Yesterday_SMA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBlWxVPdOAFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 0.0183 ± 0.0122\tOverbought_Yesterday_SMAx\n",
        "# 0.0091 ± 0.0061\tBelow_14D_SMA_Yesterday\n",
        "# 0.0061 ± 0.0000\tOversold_SMA_And_Under_14D_SMA_Yesterday\n",
        "# 0.0061 ± 0.0122\tOverbought_Yesterday_EXP\n",
        "# 0 ± 0.0000\tOversold_EXP_And_Under_14D_SMA_Yesterday\n",
        "# 0 ± 0.0000\tSMA_Yesterday\n",
        "# 0 ± 0.0000\tYear\n",
        "# -0.0061 ± 0.0000\tOversold_Yesterday_SMA\n",
        "# -0.0061 ± 0.0122\tAbove_14D_SMA_Yesterday\n",
        "# -0.0091 ± 0.0061\tOversold_Yesterday_EXP\n",
        "# -0.0091 ± 0.0427\tRSI_Yesterday_EXP\n",
        "# -0.0122 ± 0.0000\tVolume_Yesterday\n",
        "# -0.0274 ± 0.0305\tRSI_Yesterday_SMAx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTBaO5meOAFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = 'Close_Higher_Than_Yesterday'\n",
        "# drop = ['Date','Year','SMA','Volume','Adj_Close','Roll_Up','Roll_Down','Oversold_And_Under_14D_SMA_Yesterday']\n",
        "# drop = ['Date','Year','SMA','Volume','Adj_Close','Roll_Up','Roll_Down', 'Above_14D_SMA_Yesterday',\n",
        "#         'Overbought_Yesterday','RSI']\n",
        "\n",
        "# drop = ['Date','Volume','SMA','Roll_Up','Roll_Up1','Roll_Up2','Roll_Down','Roll_Down1',\n",
        "#         'Close','Roll_Down2','RSI_Yesterday_SMA','Oversold_Yesterday_EXP','SMA_Yesterday',\n",
        "#         'Year','Oversold_EXP_And_Under_14D_SMA_Yesterday','Overbought_Yesterday_EXP',\n",
        "#         'Oversold_SMA_And_Under_14D_SMA_Yesterday','Overbought_Yesterday_SMA','RSI_Yesterday_EXP',\n",
        "#         'Volume_Yesterday']\n",
        "\n",
        "\n",
        "# drop = ['Date','Volume','SMA','Roll_Up','Roll_Up1','Roll_Up2','Roll_Down','Roll_Down1',\n",
        "#         'Close','Roll_Down2','RSI_Yesterday_EXP','Volume_Yesterday','Below_14D_SMA_Yesterday',\n",
        "#         'Year','RSI_Yesterday_SMA','Overbought_Yesterday_EXP','Above_14D_SMA_Yesterday',\n",
        "#         'Overbought_Yesterday_SMA'\n",
        "#         ]\n",
        "\n",
        "# BELOW ARE STANDARD DROPS (SOME CONTAIN FUTURE LEAKAGE)\n",
        "\n",
        "# drop = ['Date','Volume','SMA','Roll_Up','Roll_Up1','Roll_Up2','Roll_Down','Roll_Down1',\n",
        "#         'Close','Roll_Down2']\n",
        "\n",
        "# BELOW IS THE DROP FOR TRAIN 1994-2013 AND VAL 2019\n",
        "\n",
        "#1\n",
        "# drop = ['Date','Volume','SMA','Roll_Up','Roll_Up1','Roll_Up2','Roll_Down','Roll_Down1',\n",
        "#         'Close','Roll_Down2','Year','Volume_Yesterday','Oversold_SMA_And_Under_14D_SMA_Yesterday',\n",
        "#         'Oversold_EXP_And_Under_14D_SMA_Yesterday','Oversold_Yesterday_EXP','SMA_Yesterday',\n",
        "#         'Oversold_Yesterday_SMA','Overbought_Yesterday_SMA','Overbought_Yesterday_EXP',\n",
        "#         'Below_14D_SMA_Yesterday','RSI_Yesterday_SMA']\n",
        "\n",
        "#2\n",
        "# drop = ['Date','Volume','SMA','Roll_Up','Roll_Up1','Roll_Up2','Roll_Down','Roll_Down1',\n",
        "#         'Close','Roll_Down2','Overbought_Yesterday_EXP','Oversold_Yesterday_SMA',\n",
        "#         'Year','SMA_Yesterday','RSI_Yesterday_SMA','Oversold_EXP_And_Under_14D_SMA_Yesterday',\n",
        "#         'Oversold_SMA_And_Under_14D_SMA_Yesterday','Oversold_Yesterday_EXP','RSI_Yesterday_EXP',\n",
        "#         'Above_14D_SMA_Yesterday']\n",
        "\n",
        "#3\n",
        "drop = ['Date','Volume','SMA','Roll_Up','Roll_Up1','Roll_Up2','Roll_Down','Roll_Down1',\n",
        "        'Close','Roll_Down2','RSI_Yesterday_SMA','Overbought_Yesterday_SMA','Volume_Yesterday',\n",
        "        'Oversold_EXP_And_Under_14D_SMA_Yesterday','Year','SMA_Yesterday','Below_14D_SMA_Yesterday',\n",
        "        'Oversold_SMA_And_Under_14D_SMA_Yesterday','Overbought_Yesterday_EXP','Oversold_Yesterday_EXP',\n",
        "        'Oversold_Yesterday_SMA','Above_14D_SMA_Yesterday']\n",
        "\n",
        "train = spy_1994_2013.drop(columns=drop)\n",
        "test = spy_2015.drop(columns=drop)\n",
        "val = spy_2019.drop(columns=drop)\n",
        "\n",
        "X_val = val.drop(columns=target)\n",
        "y_val = val[target]\n",
        "\n",
        "X_test = test.drop(columns=target)\n",
        "y_test = test[target]\n",
        "\n",
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVuCVZvaOAFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_val.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5ojhWWCOAFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kGU1gbDOAFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc7ta7VVOAFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzfbO2EnOAFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_val.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuMtSVCEOAFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=pipeline.predict(X_val)\n",
        "\n",
        "plot_confusion_matrix(y_val,y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04j6r24nOAFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxCxNf9uOAFu",
        "colab_type": "text"
      },
      "source": [
        "# Fit a model. Does it beat your baseline?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFiWXnU2OAFu",
        "colab_type": "text"
      },
      "source": [
        "### ROC AUC (GIVING GENERIC VALUES OF .5 ...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoRoYE7pOAFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# y_pred_proba = np.full_like(y_val, fill_value=1.00)\n",
        "# roc_auc_score(y_val, y_pred_proba)\n",
        "\n",
        "# y_pred_proba = np.full_like(y_val, fill_value=0)\n",
        "# roc_auc_score(y_val, y_pred_proba)\n",
        "\n",
        "# y_pred_proba = np.full_like(y_val, fill_value=0.50)\n",
        "# roc_auc_score(y_val, y_pred_proba)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6JqhdZYOAFx",
        "colab_type": "text"
      },
      "source": [
        "# BELOW THROWS ERROR:\n",
        "# UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvgKFk-9OAFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import roc_curve\n",
        "# fpr, tpr, thresholds = roc_curve(y_val=='Charged Off', y_pred_proba)\n",
        "# plt.plot(fpr, tpr)\n",
        "# plt.title('ROC curve')\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.ylabel('True Positive Rate');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juEAbsblOAFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_val.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLJL9-ybOAF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "lr = make_pipeline(\n",
        "    ce.OrdinalEncoder(), # Not ideal for Linear Regression \n",
        "    StandardScaler(), \n",
        "    LinearRegression()\n",
        ")\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "print('Linear Regression R^2', lr.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVGNnztrOAF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hibni0eeOAF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val.RSI_Yesterday_EXP.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "i-Z2xzSyOAF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val_example = X_val[X_val['RSI_Yesterday_EXP'] <= 30]\n",
        "X_val_example"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "5eOfltTzOAF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example = X_val_example.iloc[[0]]\n",
        "example"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLRoG9TCOAF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = lr.predict(example)[0]\n",
        "print(f'Predicted Probability Close Higher Today: {pred:.2f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ZbIujnMIOAF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example2 = X_val_example.iloc[[1]]\n",
        "pred2 = lr.predict(example2)[0]\n",
        "print(f'Predicted Probability Close Higher Today: {pred2:.2f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlIttqDhOAGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gp5cbgsOAGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example3 = X_val.iloc[[4]]\n",
        "pred3 = lr.predict(example3)[0]\n",
        "print(f'Predicted Probability Close Higher Today: {pred3:.2f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z45nPcDOAGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI95TGQHOAGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 72"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljr59o9WOAGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# conda install -c conda-forge category_encoders\n",
        "# pip install category_encoders\n",
        "# pip install plotly==4.1.0\n",
        "# conda install -c conda-forge eli5 \n",
        "\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "permuter = PermutationImportance(\n",
        "    model, scoring='accuracy', n_iter=2, random_state=42\n",
        ")\n",
        "\n",
        "permuter.fit(X_val, y_val)\n",
        "feature_names = X_val.columns.tolist()\n",
        "eli5.show_weights(\n",
        "    permuter,\n",
        "    top=None,\n",
        "    feature_names = feature_names\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y1X9n13OAGG",
        "colab_type": "text"
      },
      "source": [
        "# DO XGBOOST IN COLAB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRoy9wM0OAGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !conda install -c mndrake xgboost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kU4Ged6OAGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.metrics import r2_score\n",
        "# from xgboost import XGBRegressor\n",
        "\n",
        "# gb = make_pipeline(\n",
        "#     ce.OrdinalEncoder(), \n",
        "#     XGBRegressor(n_estimators=200, objective='reg:squarederror', n_jobs=-1)\n",
        "# )\n",
        "\n",
        "# gb.fit(X_train, y_train_log)\n",
        "# y_pred_log = gb.predict(X_val)\n",
        "# y_pred = np.expm1(y_pred_log)\n",
        "# print('Gradient Boosting R^2', r2_score(y_val, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlbescfBOAGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install pdpbox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xra0-_rnOAGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from pdpbox.pdp import pdp_isolate, pdp_plot\n",
        "\n",
        "# feature = 'Close'\n",
        "\n",
        "# isolated = pdp_isolate(\n",
        "#     model=gb, \n",
        "#     dataset=X_val, \n",
        "#     model_features=X_val.columns, \n",
        "#     feature=feature\n",
        "# )\n",
        "\n",
        "# pdp_plot(isolated, feature_name=feature);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4qb2CCjOAGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spy.iloc[[2]].to_string()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL9nrzsoOAGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spy.iloc[[2]]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
