{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarmen_Sinanian_assignment_applied_modeling_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarmenSinanian/DS-Unit-2-Applied-Modeling/blob/master/Sarmen_Sinanian_assignment_applied_modeling_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nCc3XZEyG3XV"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Applied Modeling, Module 1\n",
        "\n",
        "You will use your portfolio project dataset for all assignments this sprint.\n",
        "\n",
        "## Assignment\n",
        "\n",
        "Complete these tasks for your project, and document your decisions.\n",
        "\n",
        "- [ ] Choose your target. Which column in your tabular dataset will you predict?\n",
        "- [ ] Choose which observations you will use to train, validate, and test your model. And which observations, if any, to exclude.\n",
        "- [ ] Determine whether your problem is regression or classification.\n",
        "- [ ] Choose your evaluation metric.\n",
        "- [ ] Begin with baselines: majority class baseline for classification, or mean baseline for regression, with your metric of choice.\n",
        "- [ ] Begin to clean and explore your data.\n",
        "- [ ] Choose which features, if any, to exclude. Would some features \"leak\" information from the future?\n",
        "\n",
        "## Reading\n",
        "- [Attacking discrimination with smarter machine learning](https://research.google.com/bigpicture/attacking-discrimination-in-ml/), by Google Research, with  interactive visualizations. _\"A threshold classifier essentially makes a yes/no decision, putting things in one category or another. We look at how these classifiers work, ways they can potentially be unfair, and how you might turn an unfair classifier into a fairer one. As an illustrative example, we focus on loan granting scenarios where a bank may grant or deny a loan based on a single, automatically computed number such as a credit score.\"_\n",
        "- [How Shopify Capital Uses Quantile Regression To Help Merchants Succeed](https://engineering.shopify.com/blogs/engineering/how-shopify-uses-machine-learning-to-help-our-merchants-grow-their-business)\n",
        "- [Maximizing Scarce Maintenance Resources with Data: Applying predictive modeling, precision at k, and clustering to optimize impact](https://towardsdatascience.com/maximizing-scarce-maintenance-resources-with-data-8f3491133050), **by Lambda DS3 student** Michael Brady. His blog post extends the Tanzania Waterpumps scenario, far beyond what's in the lecture notebook.\n",
        "- [Notebook about how to calculate expected value from a confusion matrix by treating it as a cost-benefit matrix](https://github.com/podopie/DAT18NYC/blob/master/classes/13-expected_value_cost_benefit_analysis.ipynb)\n",
        "- [Simple guide to confusion matrix terminology](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/) by Kevin Markham, with video\n",
        "- [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LUp9Y9Q7dqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGUnBBtO7dqU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6c387c2-7107-49c6-e86a-b25198f22c5b"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orwt4IG17dqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### How do you turn importing of csv's into a function? I attempted it below with an error from using a \\###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJYgdKA37dqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# columns = ['Date','Close','Volume']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJtqW9Fc7rmx",
        "colab_type": "text"
      },
      "source": [
        "# DATASET FROM KAGGLE(HUGE STOCK MARKET DATASET): https://www.kaggle.com/borismarjanovic/price-volume-data-for-all-us-stocks-etfs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq1FNID57dqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def import_df(df_name):\n",
        "#     df_name = pd.read_csv(f'E:\\Desktop\\Lambda School\\Data Sets\\Data Visualization and Storytelling Project\\price-volume-data-for-all-us-stocks-etfs\\Data\\ETFs\\\\{df_name}',\n",
        "#                           usecols = columns)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raHgsW8C7dqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import_df('spy.us.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExuVLM107dqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = ['Date','Close','Volume']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GEIrK_77dqj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "86f6c141-d3eb-468b-c0f3-94c71b737a43"
      },
      "source": [
        "spy = pd.read_csv(f'E:\\Desktop\\Lambda School\\Data Sets\\Data Visualization and Storytelling Project\\price-volume-data-for-all-us-stocks-etfs\\Data\\ETFs\\\\spy.us.txt',\n",
        "                          usecols = columns)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-189b3fef856d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m spy = pd.read_csv(f'E:\\Desktop\\Lambda School\\Data Sets\\Data Visualization and Storytelling Project\\price-volume-data-for-all-us-stocks-etfs\\Data\\ETFs\\\\spy.us.txt',\n\u001b[0;32m----> 2\u001b[0;31m                           usecols = columns)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'E:\\\\Desktop\\\\Lambda School\\\\Data Sets\\\\Data Visualization and Storytelling Project\\\\price-volume-data-for-all-us-stocks-etfs\\\\Data\\\\ETFs\\\\spy.us.txt' does not exist: b'E:\\\\Desktop\\\\Lambda School\\\\Data Sets\\\\Data Visualization and Storytelling Project\\\\price-volume-data-for-all-us-stocks-etfs\\\\Data\\\\ETFs\\\\spy.us.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCMijRDx7dql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35p8VXE37dqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b74-nIcI7dqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vCFxE6hqF3P9"
      },
      "source": [
        "# Choose your target. Which column in your tabular dataset will you predict?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL0Z92L_7dqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PRICE(CLOSE) IS THE TARGET\n",
        "# OR PRICE(CLOSE) NEXT DAY ABOVE/BELOW PREVIOUS DAY BASED ON ROLLING MEAN(SMA) OR RELATIVE STRENGTH (RSI)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iGhy2o9MF5iK"
      },
      "source": [
        "# Choose which observations you will use to train, validate, and test your model. And which observations, if any, to exclude.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJK3MZ167dqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuMdQ76X7dqz",
        "colab_type": "text"
      },
      "source": [
        "### *WILL USE ALL SPY (S&P 500 ETF) DATA*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KwGWGEUZF5e4"
      },
      "source": [
        "# Determine whether your problem is regression or classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To5VC_Qt7dq0",
        "colab_type": "text"
      },
      "source": [
        "### *CLASSIFICATION (IS THIS TICKER OVER/UNDER THE X_DAY ROLLING MEAN ***AND*** ALSO OVER/UNDER BOUGHT ON THE RSI?)*\n",
        "### *AKA 3 WAY CONFUSION MATRIX WITH UNDER TO BOTH AS THE HIGHEST LIKELIHOOD PREDICTOR OF NEXT DAY/WEEKS/MONTHS POSITIVE RETURNS*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OE4NpAxhF5bJ"
      },
      "source": [
        "# Choose your evaluation metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emKG2y8E7dq2",
        "colab_type": "text"
      },
      "source": [
        "### WILL USE ACCURACY SCORE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k2-7u08UF5Xo"
      },
      "source": [
        "# Begin with baselines: majority class baseline for classification, or mean baseline for regression, with your metric of choice.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS4p-WOj7dq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vax0NUvq7dq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8PojzCr7dq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfQgh9D27dq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy['Date'] = pd.to_datetime(spy['Date'])\n",
        "spy['Year'] = spy['Date'].dt.year"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US3WB8NA7drB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7YZ22Dc7drL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s1N6Bhe7drO",
        "colab_type": "text"
      },
      "source": [
        "### *NEITHER .ROLLING_MEAN NOR .ROLLING WORK*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCCKgK_p7drP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spy['SMA'] = spy['Close'].rolling(window = 14, min_periods = 14, axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQjptBKP7drQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spy['SMA'] = pd.rolling_mean(spy['Close'], min_periods = 14, window = 14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J860FlcV7drS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oi9ze5M7drU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vhx1v5G7drW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MlMqGtiI7drY"
      },
      "source": [
        "# Begin with baselines: majority class baseline for classification, or mean baseline for regression, with your metric of choice.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA-VtWgl7drZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy['SMA'] = spy.Close.rolling(window=14).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wcyQqY57dra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.head(14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwQE3abV7drc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy['Below_14D_SMA_Today'] = np.where(spy['SMA']>spy['Close'], 'True','False')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwzXv0-K7dre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.Below_14D_SMA_Today.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVhK5s-C7drh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnWFYd_X7drj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WByE5n47drl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gtl5WvY7drn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spy['Close_Higher'] = np.where(spy['Close'] > spy['Close'].shift(-1), 'True','False')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq2S4Q7d7dro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spy_numeric = ['Close']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk1uUbFC7drq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy_numeric_diff = spy[['Close']].diff()[1:]\n",
        "# cond1 = spy_numeric_diff[['Close']] >=0\n",
        "spy['Close_Higher_Than_Yesterday'] = np.insert(np.where(spy_numeric_diff[['Close']] >=0, 'UP',' DOWN'), 0, '-')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9nrae2I7drs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spy.Close_Higher_Than_Yesterday.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imOnhves7drv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = spy['Close_Higher_Than_Yesterday']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ugS-SOF7drw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "majority_class = y_train.mode()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWiyuOWM7drz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = [majority_class]*len(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqpzgMCu7dr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QdLb-a_MF5ST"
      },
      "source": [
        "# Begin to clean and explore your data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeJ4ScaD7dr4",
        "colab_type": "text"
      },
      "source": [
        "### *I BELIEVE THIS IS ALREADY DONE*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAPOO5-q7dr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spy_2017 = spy[spy['Year'] == 2017]\n",
        "# spy_2016 = spy[spy['Year'] == 2016]\n",
        "# spy_2015 = spy[spy['Year'] == 2015]\n",
        "# spy_2014 = spy[spy['Year'] == 2014]\n",
        "# spy_2013 = spy[spy['Year'] == 2013]\n",
        "# spy_2012 = spy[spy['Year'] == 2012]\n",
        "# spy_2011 = spy[spy['Year'] == 2011]\n",
        "# spy_2010 = spy[spy['Year'] == 2010]\n",
        "# spy_2009 = spy[spy['Year'] == 2009]\n",
        "# spy_2008 = spy[spy['Year'] == 2008]\n",
        "# spy_2007 = spy[spy['Year'] == 2007]\n",
        "# spy_2006 = spy[spy['Year'] == 2006]\n",
        "# spy_2005 = spy[spy['Year'] == 2005]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Obnnwj487dr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Hyd8yoqF5LH"
      },
      "source": [
        "# Choose which features, if any, to exclude. Would some features \"leak\" information from the future?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ4nFjvv7dr_",
        "colab_type": "text"
      },
      "source": [
        "### *ALL FEATURES RELEVANT*"
      ]
    }
  ]
}